We investigate the rates of decay of the prediction error for kernel methods
under the Gaussian design and source/capacity assumptions. For kernel ridge
regression, we derive all the observable rates, and characterize the regimes in
which each hold. In particular, we show that the decay rate may transition from
a fast, noiseless rate to a slow, noisy rate as the sample complexity is
increased. For noiseless kernel classification, we derive the rates for two
standard classifiers, margin-maximizing SVMs and ridge classifiers, and contrast
the two methods. In both cases, the derived rates also describe to a good degree
the learning curves of a number of real datasets.