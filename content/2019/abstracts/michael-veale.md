Cryptosystems for privacy-preserving data analysis are often motivated by a desire to analyse data that is held by a range of actors that wish to keep it private either because their own privacy is at stake, or they are legally or ethically obliged to do so on behalf of others. The premise for much encrypted data analysis is that there are a range of functions which would take components from two or more of these datasets as input, and produce an output that would broadly not be seen as private. But, how far does this help actors mitigate or even escape obligations, particularly those under European data protection law? In this talk, I will analyse techniques and applications of secure multiparty computation, homomorphic encryption and zero-knowledge proofs in the context of the GDPR, considering in particular the ways these technologies can be purposed to make coercive systems for users, rather than just protective ones. In many cases, these technologies sit uneasily with the framework as we see it today: they do not fall out the scope of the law, but arguably, neither are users sufficiently protected against developers of cryptosystems seeking to force users to perform potentially manipulative protocols.
